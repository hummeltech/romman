#!/usr/bin/env python3

import logging
import romman
from sys import exit
import argparse
from os.path import join

TOOL_NAME = "Romman"
DEFAULT_DATASHEETS_DIRECTORY= "./Datasheets"
DEFAULT_NOINTRO_DIRECTORY = join(DEFAULT_DATASHEETS_DIRECTORY, "nointro")
DEFAULT_REDUMP_DIRECTORY = join(DEFAULT_DATASHEETS_DIRECTORY, "redump")
DEFAULT_TOSEC_DIRECTORY = join(DEFAULT_DATASHEETS_DIRECTORY, "tosec")

log = logging.getLogger()
log.setLevel(logging.INFO)
handler = logging.StreamHandler()
handler.setFormatter(logging.Formatter(fmt='[%(asctime)s][%(name)s][%(levelname)s] %(message)s', datefmt='%H:%M:%S'))
log.addHandler(handler)

#argparse shenanigans
ap = argparse.ArgumentParser()
ap.add_argument("items", help="Path to ROM file or directory with ROMs to compare with database. Can be multiple. If directory - will fetch content from all subdirectories", nargs='+', type=str)
ap.add_argument("--datfiles", help="Custom path to data file or directory with data files, used to compare ROMs with instead of default. Can be multiple. Also process subdirectories", nargs='*', type=str)
ap.add_argument("--debug", help="Add debug messages to program's output", action="store_true")
args = ap.parse_args()

if args.debug:
    log.setLevel(logging.DEBUG) #Overriding default value from above

if args.datfiles:
    datasheets = args.datfiles
    log.debug(f"Attempting to load {args.datfiles} instead of default datasheets")
else:
    datasheets = [DEFAULT_DATASHEETS_DIRECTORY]

log.info("Loading the database")
data_files = []
for item in datasheets:
    try:
        df = romman.file_processing.get_files(item)
    except Exception as e:
        log.warning(f"Couldnt process datasheets on path {item}: {e}")
        continue
    else:
        data_files.extend(df)

if not data_files:
    log.critical(f"Couldnt find any valid data files! Abort")
    exit(1)

database = []
for item in data_files:
    try:
        data = romman.data_parsers.dat_file(item)
    except Exception as e:
        log.warning(f"Couldnt process data file {item}: {e}")
    else:
        database.extend(data)

if not database:
    log.critical(f"Couldnt find any valid database entries! Abort")
    exit(1)

log.info("Getting the filelist from provided arguments")
filepaths = []
for item in args.items:
    try:
        f = romman.file_processing.get_files(item)
    except Exception as e:
        log.warning(f"Couldnt get files from {item}: {e}. Skipping")
        continue
    else:
        filepaths.extend(f)

log.info("Calculating hash sums of provided files")
files = []
for item in filepaths:
    try:
        crc = romman.hashcheck.crc32sum(item)
    except Exception as e:
        log.warning(f"Couldnt get hash of {item}: {e}. Skipping")
        continue
    else:
        data = {}
        data['file'] = item
        data['crc'] = crc
        files.append(data)

if not files:
    log.critical(f"No valid file entries has been received! Abort")
    exit(1)

log.debug(f"Got following files to process: {files}")
#This will only find the very first match. If file exists in multiple datsheets - the rest will be ignored
matches = 0
for item in files:
    for entry in database:
        if item['crc'] == entry['crc']:
            log.info(f"{item['file']} match {entry['name']} in {entry['group']} of {entry['category']}!")
            matches += 1
            break #this only breaks "for entry" cycle - "for item" continues with next file

errors = len(filepaths) - len(files)
misses = len(files) - matches

print(f"{TOOL_NAME} has finished its job: got {matches} hits, {misses} misses and {errors} errors")
