#!/usr/bin/env python3

import logging
import romman
from sys import exit
import argparse
from os.path import join

TOOL_NAME = "Romman"
DEFAULT_DATASHEETS_DIRECTORY= "./Datasheets"
DEFAULT_NOINTRO_DIRECTORY = join(DEFAULT_DATASHEETS_DIRECTORY, "nointro")

log = logging.getLogger()
log.setLevel(logging.INFO)
handler = logging.StreamHandler()
handler.setFormatter(logging.Formatter(fmt='[%(asctime)s][%(name)s][%(levelname)s] %(message)s', datefmt='%H:%M:%S'))
log.addHandler(handler)

#argparse shenanigans
ap = argparse.ArgumentParser()
ap.add_argument("items", help="Path to ROM file or directory with ROMs to compare with database. Can be multiple. If directory - will fetch content from all subdirectories", nargs='+', type=str)
ap.add_argument("--datfiles", help="Custom path to data file or directory with data files, used to compare ROMs with instead of default. Can be multiple. Also process subdirectories", nargs='*', type=str)
ap.add_argument("--debug", help="Add debug messages to program's output", action="store_true")
args = ap.parse_args()

if args.debug:
    log.setLevel(logging.DEBUG) #Overriding default value from above

if args.datfiles:
    datasheets = args.datfiles
    log.debug(f"Attempting to load {args.datfiles} instead of default datasheets")
else:
    datasheets = [DEFAULT_DATASHEETS_DIRECTORY]

log.info("Loading the database")
data_files = []
for item in datasheets:
    try:
        df = romman.file_processing.get_files(item)
    except Exception as e:
        log.warning(f"Couldnt process datasheets on path {item}: {e}")
        continue
    else:
        data_files.extend(df)

if not data_files:
    log.critical(f"Couldnt find any valid data files! Abort")
    exit(1)

database = []
for item in data_files:
    try:
        data = romman.data_parsers.nointro(item)
        data['category'] = 'No-Intro'
        data['hash'] = romman.hashcheck.crc32sum(item)
    except Exception as e:
        log.warning(f"Couldnt process data file {item}: {e}")
    else:
        database.append(data)

if not database:
    log.critical(f"Couldnt find any valid database entries! Abort")
    exit(1)

log.info("Getting the filelist from provided arguments")
filepaths = []
for item in args.items:
    try:
        f = romman.file_processing.get_files(item)
    except Exception as e:
        log.warning(f"Couldnt get files from {item}: {e}. Skipping")
        continue
    else:
        filepaths.extend(f)

log.info("Calculating hash sums of provided files")
files = []
for item in filepaths:
    try:
        crc = romman.hashcheck.crc32sum(item)
    except Exception as e:
        log.warning(f"Couldnt get hash of {item}: {e}. Skipping")
        continue
    else:
        data = {}
        data['file'] = item
        data['crc'] = crc
        files.append(data)

if not files:
    log.critical(f"No valid file entries has been received! Abort")
    exit(1)

log.debug(f"Got following files to process: {files}")
#This creates list of all files known to database
#I should probably redesign the whole way I add new entries to database list, coz this is a clusterfuck
known_files = [f for item in database for entry in item['content'] for f in entry['files']]

#I should get rid of lists comprehension there too, coz idk how to log things with that being there
matching_files = [item for item in files for entry in known_files if item['crc'] == entry['crc']]

matches = len(matching_files)
misses = len(filepaths) - matches

print(f"{TOOL_NAME} has finished its job: got {matches} files matching provided database and {misses} misses")
print("Done")
