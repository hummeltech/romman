#!/usr/bin/env python3

## Romman - yet another tool to compare your console ROMs with accuracy-focused datasheets
## Copyright (c) 2021 moonburnt
##
## This program is licensed under Anti-Capitalist Software License.
## For terms and conditions, see attached LICENSE file.

import logging
import romman
from sys import exit
import argparse
from os import makedirs
from os.path import join

TOOL_NAME = romman.configuration.TOOL_NAME
LAUNCHER_NAME = f"{TOOL_NAME}-cli"
PROGRAM_DIRECTORY = romman.configuration.PROGRAM_DIRECTORY
CACHE_DIRECTORY = romman.configuration.CACHE_DIRECTORY
DEFAULT_DATASHEETS_DIRECTORY = romman.configuration.DEFAULT_DATASHEETS_DIRECTORY

NOINTRO_PREFIX = romman.configuration.NOINTRO_PREFIX
REDUMP_PREFIX = romman.configuration.REDUMP_PREFIX
TOSEC_PREFIX = romman.configuration.TOSEC_PREFIX
MAME_PREFIX = romman.configuration.MAME_PREFIX

log = logging.getLogger()
log.setLevel(logging.INFO)
handler = logging.StreamHandler()
handler.setFormatter(logging.Formatter(fmt='[%(asctime)s][%(name)s][%(levelname)s] %(message)s', datefmt='%H:%M:%S'))
log.addHandler(handler)

#argparse shenanigans
ap = argparse.ArgumentParser()
ap.add_argument("items", help=f"Path to ROM file or directory with ROMs to compare with database. You can supply multiple paths at once. If directory - {TOOL_NAME} will also seek for ROMs in its subdirectories", nargs='*', type=str)
ap.add_argument("--datfiles", help=f"Custom path to datasheet file or directory with datasheets. If used - {TOOL_NAME} will compare ROMs with these instead of default datasheets. You can supply multiple paths at once. If directory - {TOOL_NAME} will also seek for datasheets in its subdirectories", nargs='*', type=str)
ap.add_argument("--debug", help=f"Add debug messages to {TOOL_NAME}'s output", action="store_true")
ap.add_argument("--update-datfiles", help=f"Download latest available datasheets. Can be used with provider-specific prefixes. If no valid prefixes has been received - will batch-download datasheets from all supported providers. Valid prefixes are the following: {NOINTRO_PREFIX}, {REDUMP_PREFIX}, {TOSEC_PREFIX}, {MAME_PREFIX}", nargs='*', type=str)
args = ap.parse_args()

if args.debug:
    log.setLevel(logging.DEBUG) #Overriding default value from above

#this is nasty as hell, but thats the best way to ensure that args.update_datfiles has been passed
#even if its empty. Or at least out of solutions I've found. Maybe there is better
try:
    len(args.update_datfiles)
except:
    pass
else:
    log.info("Updating the database (may take some time)")
    romman.dat_updater.datasheets_updater(args.update_datfiles)
    log.info("Successfully updated the database!")

if not args.items:
    print(f"Got no ROMs to verify! For usage info, see {LAUNCHER_NAME} -h")
    exit(0)

if args.datfiles:
    datasheets = args.datfiles
    log.debug(f"Attempting to load {args.datfiles} instead of default datasheets")
else:
    datasheets = [DEFAULT_DATASHEETS_DIRECTORY]

log.info("Loading the database")
data_files = []
for item in datasheets:
    try:
        df = romman.file_processing.get_files(item)
    except FileNotFoundError as e:
        #ensuring that directory we will reffer to in message below exists
        #I know this looks ugly, maybe will find a better solution later
        if item == DEFAULT_DATASHEETS_DIRECTORY:
            makedirs(DEFAULT_DATASHEETS_DIRECTORY, exist_ok=True)
        else:
            log.warning(f"{item} doesnt exist. Skipping")
            continue
    except Exception as e:
        log.warning(f"Couldnt process datasheets on path {item}: {e}. Skipping")
        continue
    else:
        data_files.extend(df)

if not data_files:
    log.critical(f"Couldnt find any valid data files! Either place them manually into {DEFAULT_DATASHEETS_DIRECTORY} or run {LAUNCHER_NAME} --update-datfiles to download latest datasheets from supported sources")
    exit(1)

database = []
for item in data_files:
    #this check is meh, but important - applying wrong parser to wrong file worthy hundreds of mbytes may eat all ram
    if item.endswith('.dat'.lower()):
        log.debug(f"Guessing that {item} is standard .dat file and proceeding accordingly")
        parser = romman.data_parsers.dat_file
    elif item.endswith('.xml'.lower()):
        log.debug(f"Guessing that {item} is mame .xml file and proceeding accordingly")
        parser = romman.data_parsers.mame_xml
    else:
        log.warning(f"Couldnt process data file {item}: unknown file format")
        continue

    try:
        data = parser(item)
    except Exception as e:
        log.warning(f"Couldnt process data file {item}: {e}")
        continue


    else:
        database.extend(data)

if not database:
    log.critical(f"Couldnt find any valid database entries! Abort")
    exit(1)

log.info("Getting the filelist from provided arguments")
filepaths = []
for item in args.items:
    try:
        f = romman.file_processing.get_files(item)
    except Exception as e:
        log.warning(f"Couldnt get files from {item}: {e}. Skipping")
        continue
    else:
        filepaths.extend(f)

log.info("Calculating hash sums of provided files")
files = []
for item in filepaths:
    try:
        data = romman.file_processing.file_processor(item)
    except Exception as e:
        log.warning(f"Couldnt get hash of {item}: {e}. Skipping")
        continue
    else:
        files.extend(data)

if not files:
    log.critical(f"No valid file entries has been received! Abort")
    exit(1)

log.debug(f"Got following files to process: {files}")
#This will only find the very first match. If file exists in multiple datsheets - the rest will be ignored
matches = 0
for item in files:
    for entry in database:
        try:
            #I should probably bring everything to lowercase while fetching hashes from datasheets
            #thus said - "if it works, it works", even if it may be less resource-efficient
            if item['crc'] == entry['crc'].lower():
                log.info(f"{item['path']} match {entry['name']} in {entry['group']} of {entry['category']}!")
                matches += 1
                break #this only breaks "for entry" cycle - "for item" continues with next file
        except Exception as e:
            log.warning(f"Couldnt compare {item['path']} with {entry['name']}: {e}. Skipping")
            continue

errors = len(filepaths) - len(files)
misses = len(files) - matches

print(f"{TOOL_NAME} has finished its job: got {matches} hits, {misses} misses and {errors} errors")
